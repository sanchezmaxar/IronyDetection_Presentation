
\chapter{Introducción}\label{cap.introduccion}
\pagenumbering{arabic}
\setcounter{page}{1}
\onehalfspacing

\par La ironía es una figura retórica que consiste en decir lo contrario de lo que se quiere dar a entender; esta definición es a veces difícil de entender para una persona y por lo tanto es de esperarse que es más difícil de hacer entender a un sistema de cómputo. Hasta este momento, se le puede dar a una computadora un conjunto de instrucciones específicas, y si se logra definir de algún modo las intenciones, se puede hacer que una computadora entienda de forma concreta un concepto. Sin embargo, la ironía reta a la lógica y es difícil para una persona explicar si una oración es irónica o es algo literal, muchas veces esto depende del contexto. Es cuando entra la inteligencia artificial, que ayuda a no explicar cosas que no se entienden bien o que dependen de muchas condiciones y hace que el sistema computacional salte la barrera de la lógica dotándola de procesos que simulan el razonamiento humano. La inteligencia artificial se ha usado en otras tareas como conducir un automóvil, clasificar objetos, darle significado a las palabras, entre otras.

\par La ironía como un recurso lingüístico se destaca entre otras por su facilidad para satisfacer al lector; dando un valor agregado a la comunicación, si aparece como sátira provoca una risa casi instantánea, si aparece como sarcasmo suele ser más hiriente, incluso suele hacer pensar en las implicaciones de lo que se atreve uno a decir, como en el siguiente ejemplo:

\begin{center}
	\textit{``... En otra ocasión Borges firmaba ejemplares en una librería del Centro. Un joven se acercó con Ficciones y le dijo: `Maestro, usted es inmortal'... Borges le contestó: `Vamos, hombre, no hay por qué ser tan pesimista'."} \textcite{Sergio2012}
	\vspace{5pt}
\end{center}
\vspace{5pt}

\par Este ejemplo ilustra muy bien el impacto de la ironía, de cierta forma maximiza la idea que el autor desea. Este impacto suele aportar una mayor carga de información y por lo tanto más interés en conseguirla. Ésta es una de las motivaciones que han tenido diferentes grupos de estudio para abordar la clasificación de la ironía.

\par Para hablar de las motivaciones que este problema ha tenido para analizarse, se puede empezar por ver el trabajo de \textcite{maynard2014cares} quienes se orientan por el análisis de sentimientos en redes sociales cuando este recurso es utilizado; para \textcite{utsumi1995interpret} fue uno de los primeros trabajos que se hicieron en este tema y su motivo para realizar un sistema fue para proveer de herramientas a los sistemas de \textit{procesamiento de lenguaje natural} NLP (\textit{Natural Language Processing}) y que pudieran manejar la ironía de manera correcta, este sistema consistía en un conjunto de reglas de emociones; \textcite{davidov2010semi} crean un sistema semi supervisado el cual tiene buen desempeño y resuelve la clasificación en inglés, algunos de sus motivos fue el monitoreo de marcas, resumen de reseñas, sistemas de diálogo y proponen un marco de referencia para crear estos sistemas con detección de sarcasmo.
%Aqui va la intro de los antecedentes
\par El problema de la clasificación de la ironía reside en su característica de comprimir ideas en un pequeño conjunto de palabras, como en el siguiente ejemplo:

\begin{center}
	\textit{Me encanta discutir por las mañanas por dios es algo tan :)}\\[6pt]
	\footnotesize{Twitter id 631446828127506432}
\end{center}


\par De esta pequeña frase manualmente se pueden extraer las siguientes ideas: La persona no está encantada y a la persona no le gusta discutir. En este ejemplo se pueden extraer dos ideas aparte de la que por sí sola expresa la frase, y en un contexto general ésta no tiene importancia. El siguiente ejemplo expone un caso mucho más complejo:

\begin{center}
	\textit{Empieza un bonito día...  Selectividad2015}\\[6pt]
	\footnotesize{Twitter id 608133042348130304}
\end{center}


\par Esta frase, al contrario de la anterior, requiere de un contexto para saber que es irónica, ya que la \textit{Selectividad} es un examen que se aplica en España para acceder a la educación universitaria. De esta frase se pueden extraer las siguientes suposiciones: la persona se siente nerviosa por el examen, la persona preferiría empezar su día con otra actividad, la \textit{Selectividad} es un examen difícil, etc. En este ejemplo se necesita de un contexto que ayude a intuir hacia dónde va dirigida la idea que se quiere comunicar y a la vez esta idea genera más ideas relacionadas con un contexto general, por ejemplo: \textit{A nadie le gustan las pruebas}, \textit{Las personas le tienen miedo al fracaso}, etc.

\par La extracción de información es un problema muy complejo y consiste en el estudio de un texto y la inferencia de la idea. En general la ironía interfiere en esta extracción introduciendo ruido a la inferencia, ya que aunque la ironía en forma de sarcasmo representa un pequeño porcentaje según \textcite{liu2007low}, modifica la inferencia por ser una figura lingüística que no puede ser tomada literalmente; aquí, como sugerencia, puede omitirse o invertirse la polaridad de la idea (si es que esto se quiere obtener). Por ejemplo en la extracción de reseñas se pueden tomar como negativas, debido a que la mayoría de las veces que se usa el sarcasmo (tipo de ironía que consiste en herir), es para dañar o para dar una mala opinión. Esto dependerá del área de estudio en donde se desee aplicar un modelo de extracción de información. Sin embargo, la parte central de esto es la detección de la ironía.

\section{Análisis de los métodos utilizados}
\par Algunos investigadores se han enfocado más en cómo se entiende la ironía en el área de las humanidades, encontrando cómo deben de ubicarse los verbos, sustantivos, adjetivos, etc. Otros se han enfocado en su aplicación en el mundo real, tratando de encontrar los mejores resultados. Los métodos que han sido utilizados pueden clasificarse en las categorías que muestra la tabla \ref{tab:metodos}.

\begin{table}[h]
	\caption{Algunos de los métodos que se han utilizado para clasificar la ironía.}
	\begin{tabular}{|l|p{0.8\linewidth}|}
		\hline
		Clasificación       & Artículos                                                                                                                       \\
		\hline
		Orientados a reglas & \begin{tabular}[c]{p{0.8\linewidth}} \textit{Formalization and rules for recognition of satirical irony
			} \textcite{kong2011formalization} \\ \textit{How to interpret irony by computer: A comprehensive framework for irony} \textcite{utsumi1995interpret}\end{tabular}                                                                                                       \\ \hline
		Supervisado         & \begin{tabular}[c]{p{0.8\linewidth}} \textit{Making objective decisions from subjective data: Detecting irony in customers reviews (POS+features; NB,SVM,DT)}\textcite{reyes2012making} \\ \textit{The perfect solution for detecting sarcasm in tweets \#not (Winnow Classification)} \textcite{liebrecht2013perfect}\\ \textit{Humans require context to infer ironic intent (so computers probably do, too) (SVM)} \textcite{wallace2014humans}\\ \textit{Italian irony detection in Twitter:a first approach (DT)} \textcite{barbieri2014italian}\\ \textit{Detecting irony on greel political Tweets: A text mining approach (J48, NB, FT, KStar, Random Forests)} \textcite{charalampakis2015detecting}
			\\ \textit{Character and word baselines for irony detection in spanish short texts}(SVM;RF) \textcite{lopez2016character}\end{tabular}                                                                                                       \\ \hline
		Semi-supervisados   & \textit{Semi-supervised recognition of sarcastic sentences in Twitter and Amazon (HFW,CW,KNN-like)} \textcite{davidov2010semi}. \\ \hline
		% Existe otro no supervisado sin embargo a mi parecer es truculento ya que únicamente hace embeddings, y tiene un desempeño relativamente bajo, comparado con los otros
	\end{tabular}
	\label{tab:metodos}
\end{table}

\subsection{Orientados a reglas}
\par En los métodos utilizados están los que requieren de la programación de reglas. Estos métodos también son supervisados, pero se diferencian en que requieren una mayor intervención del experto. Los sistemas basados en reglas pueden utilizar varios paradigmas como lógica difusa, lógica booleana, etc. Lo importante de estos métodos es que permiten encontrar una respuesta clara del por qué esa muestra ha sido clasificada como irónica o no. Para estos métodos suelen utilizarse herramientas como etiquetas \gls{POS} que ayudan a la clasificación de las palabras dentro de una clase como adjetivos, verbos, adverbios, sustantivos, etc. Esto sirve, por ejemplo, para dar una descripción de cómo se puede encontrar una sentencia irónica. Una desventaja de estos métodos es que se necesita un experto para la generación de reglas, aunque hay algunos casos de sistemas que pueden generar reglas de manera automática tales como el de \textcite{mitra1995fuzzy}. La desventaja es que en estos casos, si los sistemas son muy sensibles, pueden generar reglas muy generales que expliquen cosas comunes del idioma e irrelevantes para la tarea, o muy específicas de una oración en particular, como el propuesto por \textcite{kotsiantis2007supervised}. Como se puede ver, es un método poderoso para la interacción con una persona, y tal vez de más ayuda cuando se quiere modelar una lengua de manera analítica. Sin embargo, carece de adaptabilidad, ya que si se cambia el idioma o el contexto, como lo hacen las redes sociales, todo el sistema debe volver a crearse. Los principales expositores de este método son \textcite{kong2011formalization} para el idioma chino  y \textcite{utsumi1995interpret} para el idioma inglés.

\subsection{Supervisados}

\par En esta categoría está el método que se propone en esta tesis. Los métodos supervisados son aquellos que requieren de datos de entrenamiento etiquetados para poder encontrar el modelo adecuado. Los datos deben ser etiquetados por expertos los cuales puedan distinguir a qué clase pertenece una muestra; estos métodos suelen necesitar muchas muestras y un tiempo de entrenamiento considerable. La eficiencia del modelo va a depender de la destreza de los expertos para clasificar las muestras, por lo que aún es susceptible a fallos. En esta categoría se encuentran métodos que usan etiquetas \gls{POS} para encontrar características de las muestras, como lo hace \textcite{reyes2012making}. Después de este preproceso se pasa a un clasificador como \gls{SVM}, \gls{NB} y \gls{DT}; en el caso de \textcite{reyes2012making} se extrajeron 6 características de las muestras:  etiquetas \gls{POS}, perfil divertido, perfil negativo/positivo, perfil afectivo y perfil de agrado. Una vez con las características y una función de mapeo que transforme las palabras a este conjunto de características, se puede usar un clasificador como los antes mencionados.
Aquí las diferentes aproximaciones se concentran en el idioma ingles, griego, italiano y español, los investigadores que usan esta métodos supervisados son \textcite{charalampakis2015detecting}, \textcite{barbieri2014italian} y \textcite{lopez2016character} respectivamente, el presente trabajo se centrará en la detección de ironía en español como lo propone \textcite{lopez2016character}.

\subsection{Semi-supervisados}

\par Los métodos semi-supervisados son aquellos que no requieren la intervención de los expertos. A esta clasificación pertenece únicamente un trabajo previo, el trabajo de \textcite{davidov2010semi} que consiste en dos fases: adquisición de patrones de un conjunto pequeño de muestras etiquetadas del 1 al 5, de nada sarcástico a completamente sarcástico,  y la fase de clasificación. Para obtener los patrones del conjunto de muestras etiquetadas se clasifican las palabras en \gls{HFW} y \gls{CW}, lo cual denota cuales son las palabras más relevantes, basado en con que frecuencia aparece una palabra y que palabras tienen contenido y no son solo de uso gramatical. Al momento de extraer los patrones se ven similar a los mostrados en la tabla \ref{tab:ejemplo}.
\begin{center}
	\begin{table}[h]
		\caption{\footnotesize{Ejemplo de cómo se ve un patrón en este sistema; como se puede ver, los dos ejemplos pueden aparecer simultáneamente en una misma oración. Notesé que las palabras [COMPANY] y los símbolos de puntuación como el punto son \gls{HFW}. Extraído de \textcite{davidov2010semi}}}
		\label{tab:ejemplo}
		\begin{tabular}{|p{6.5cm}|p{7cm}|}
			\hline
			Frase original & Patrones encontrados                              \\
			\hline
			\multirow{4}{6cm}{Garmin apparently does not care much about product quality or customer support}
			               & \tabitem \textit{[COMPANY] CW does not CW much}   \\
			               & \tabitem \textit{does not CW much about CW CW or} \\
			               & \tabitem \textit{not CW much}                     \\
			               & \tabitem \textit{about CW CW or CW CW.}           \\
			\hline
		\end{tabular}
	\end{table}
\end{center}
\par Estos patrones sirven para después convertir las muestras del conjunto no etiquetado en vectores que describan la posición de ese patrón en un espacio de características. La clasificación es tan fácil como medir la distancia euclidiana, contar cuántos son no sarcásticos y cuántos son sarcásticos en su vecindad, y asignar una clase dependiendo del promedio de su distancia. Así, si la muestra está rodeada de muestras sarcásticas, será sarcástica completamente, y cuando esté entre un conjunto de muestras que algunas son sarcásticas y algunas no, se le asignará una clase porcentual, que indica qué tan sarcástica es.

\section{Análisis de los corpus utilizados}

\par Para el empleo de los métodos supervisados se deben obtener primero los datos que constituyen la base de conocimiento para el sistema. Estos datos aportarán ejemplos de como se encuentran normalmente las muestras. Esta base de conocimiento pueden ser imágenes, textos, audios, señales, entre otros. A la base de conocimiento también se le conoce como \textit{corpus}.

\par El corpus en general no cambia mucho de una investigación a otra, como muestra la tabla \ref{tab:corpuses},. La mayoría de los corpus están compuestos por textos provenientes de Twitter, ya que provee herramientas simples\footnote{\url{https://developer.twitter.com/}} para extraer tweets automáticamente. También suelen utilizarse corpus de Amazon ya que tienen una \gls{API} para extraer textos\footnote{ \url{https://developer.amazon.com/services-and-apis}}. Hablando de los idiomas sobre los que se han aplicado, está el chino, inglés, holandés, italiano, griego y por último el español, idioma del corpus de este estudio.

\par Otro ámbito importante de estos experimentos es que consideran un corpus no balanceado, debido a que, de acuerdo con \textcite{reyes2012making}, \textcite{lopez2016character} y \textcite{barbieri2014italian}, muestran una clara diferencia entre la cantidad de muestras irónicas o sarcásticas de las que no, por lo que se permite inferir que la proporción del uso de la ironía o sarcasmo es de aproximadamente el 12\%. Resulta importante conocer esto, ya que aporta información sobre la naturaleza del problema y ayuda a decidir mejor cómo es que debe abordarse.

\par En la mayoría de las investigaciones que obtuvieron su propio corpus, éste debió pasar por un proceso de normalización donde se removían datos irrelevantes como links de internet, caracteres especiales que no aportan información como '@' y '\#' como lo hizo \textcite{lopez2016character}. Muchas veces se utiliza un conjunto de palabras que se ignoran llamadas \textit{\gls{stopwords}} como en el caso de \textcite{reyes2012making}. En adición a esto, algunos autores añadieron el uso de \textit{\gls{tf-idf}}, que ayuda a medir la importancia de una palabra en un documento, dependiendo de cómo aparece en el documento y qué tanto aparece en el corpus completo, como el caso de \textcite{reyes2012making}, \textcite{wallace2015sparse} y \textcite{bamman2015contextualized}. Muchas veces los métodos de extracción de información también atrapan documentos repetidos y éstos deben reducirse a mano o crear algún sistema que los detecte y los borre, como en el caso de \textcite{charalampakis2015detecting} y \textcite{reyes2012making}. En el caso de \textcite{ptavcek2014sarcasm} obtuvieron características del texto como los \gls{n-grams}, etiquetas \gls{POS}, patrones con \gls{HFW}, otras como emoticones, signos de puntuación y otras características de los caracteres como el número de mayúsculas, minúsculas, etc. Todo esto lo aplicó a un corpus en checo, de 325 muestras sarcásticas y 6,675 no sarcásticos, y otro en inglés; el corpus en inglés balanceado fue de 50,000 cada clase y el no balanceado fue de 25,000 sarcásticos y 75,000 no sarcásticos.
\begin{table}[h]
	\caption{Descripción de los corpus de experimentos anteriores.}
	\begin{tabular}{|p{5cm}p{2cm} l >{\raggedleft\arraybackslash}p{3cm}|}
		\hline
		\multicolumn{1}{|l|}{Artículo}                                                                                   & \multicolumn{1}{l|}{Fuente}     & \multicolumn{1}{l|}{Idioma} & Tamaño                                                \\ \hline
		\hline
		Semi-supervised Recognition of Sarcastic Sentences in Twitter and Amazon \textcite{davidov2010semi}              & Twitter \& Amazon               & Inglés                      & 5.9 millones tweets \& 66,000 reseñas                 \\ \hline
		Making Objective Decisions from Subjective Data: Detecting Irony in Customers Reviews \textcite{reyes2012making} & Amazon, Slashdot \& TripAdvisor & Inglés                      & 3,163 $\rightarrow$ 2,861 reseñas                     \\ \hline
		The prefect solution for detecting sarcasm in tweets \#not \textcite{liebrecht2013perfect}                       & Twitter                         & Holandés                    & 3.3 millones de tweets                                \\ \hline
		Humans Require Context to Infer Ironic Intent (so Computers Probably do, too) \textcite{wallace2014humans}       & Reddit                          & Inglés                      & 3,020 comentarios                                     \\ \hline
		Italian Irony Detection in Twitter: a First Approach \textcite{barbieri2014italian}                              & Twitter                         & Italiano                    & 25,450 tweets (12.5\%/87.5\%)                         \\ \hline
		Detecting Irony on Greek Political Tweets: A Text Mining Approach \textcite{charalampakis2015detecting}          & Twitter                         & Griego                      & 61,427 tweets $\rightarrow$ 44,438 tweets             \\ \hline
		Character and Word Baselines for Irony Detection in Spanish Short Texts \textcite{lopez2016character}            & Twitter                         & Español(30/70)              & 14, 511 tweets irónicos \& 33, 859 tweets no irónicos \\ \hline
		SOUKHRIA: Towards an Irony Detection System for Arabic in Social Media \textcite{karoui2017soukhria}             & Twitter                         & Arabe                       & 1,733 tweets irónicos \& 3,746 tweets no irónicos1    \\ \hline
		Sarcasm Detection on Czech and English Twitter \textcite{ptavcek2014sarcasm}                                     & Twitter                         & Checo/Inglés                & Checo 325/6,675, Inglés (50/50) y (25/75)             \\ \hline
	\end{tabular}
	\label{tab:corpuses}
\end{table}
%--------------------------Omito estos a proposito------------------------
% 		
% 		\subsection{Análisis de las herramientas usadas}
% 		%aqui va la parte del analisis de las herramientas usadas
% 		\subsection{Análisis del preprocesamiento}
% 		%aqui va la parte del analisis del preprocesamiento
%--------------------------Omito estos a proposito------------------------

\section{Análisis de resultados}

\par En la tabla \ref{tab:resultados} se muestra cómo la mayoría de los trabajos previos han hecho sus experimentos sobre los datos de Twitter. Además, la mayoría han utilizado un método de aprendizaje supervisado y solo uno semi-supervisado, \textcite{davidov2010semi}. Se puede ver también que la distribución de datos está sesgada a que el sarcasmo/ironía aparezca la menor de las veces, como lo menciona \textcite{liu2007low} para su corpus de Amazon; esto parece aplicar también para Twitter.


\begin{table}[!ht]
	\begin{tabular}{|l|l|l|l|l|>{\raggedleft\arraybackslash}p{4cm}|}
		\hline
		Investigadores                  & P     & R     & A      & F1    & Detalles                                                                                  \\ \hline
		\textcite{davidov2010semi}      & 0.912 & 0.756 & 0.947  & 0.827 & Corpus no balanceado (471/5020), método  KNN-like, datos de Amazon                        \\ \hline
		\textcite{reyes2012making}      & 0.771 & 0.725 & 0.7575 & 0.747 & Corpus balanceado, método SVM, datos de  Amazon                                           \\ \hline
		\textcite{liebrecht2013perfect} & NA    & 0.75  & NA     & NA    & Corpus balanceado, método Winnow, datos de Twitter                                        \\ \hline
		\textcite{liebrecht2013perfect} & NA    & 0.56  & NA     & NA    & Corpus no balanceado (25/75), método Winnow, datos de Twitter                             \\ \hline
		\textcite{barbieri2014italian}  & 0.75  & 0.76  & NA     & 0.76  & Corpus no balanceado (12/88), método \gls{DT}, datos de  Twitter                          \\ \hline

		\textcite{ptavcek2014sarcasm}   & NA    & NA    & NA     & 0.923 & Corpus no balanceado (25/75), método  MaxEnt, datos de Twitter inglés                     \\ \hline
		\textcite{ptavcek2014sarcasm}   & NA    & NA    & NA     & 0.582 & Corpus no balanceado (325/6675), método  SVM, datos de Twitter checo                      \\ \hline
		\textcite{poria2016deeper}      & NA    & NA    & NA     & 0.948 & Corpus no balanceado (25/75), método  CNN-SVM, datos de Twitter                           \\ \hline
		\textcite{lopez2016character}   & NA    & NA    & NA     & 0.80  & Análisis hecho a nivel carácter con un corpus no balanceado, método SVM, datos de Twitter \\ \hline       \textcite{lopez2016character}      & NA        & NA     & NA        & 0.80     & Análisis hecho a nivel carácter con un corpus no balanceado, método RF, datos de Twitter                                                                                       \\ \hline
	\end{tabular}
	\caption{Algunos resultados de otros investigadores, P  = precisión, R = reclamo, A = exactitud, F1 = valor-F. Estas métricas se explicarán a fondo en el capítulo \ref{cap.metodologia}.}
	\label{tab:resultados}
\end{table}

%aqui va la parte del analisis de resultados
\par Después de ver más de cerca los resultados que reportan estos investigadores, se puede notar que los mejores resultados parecen ser los de \textcite{poria2016deeper} cuando usa CNN combinado con SVM y obtiene un valor de  \gls{F-score} de 0.948, que comparado con la mayoría es más grande. Este estudio fue la continuación del trabajo de \textcite{ptavcek2014sarcasm}, el cual consistía en obtener principalmente las características más relevantes como los \gls{n-grams}, etiquetas \gls{POS}, patrones con \gls{HFW}, otras como emoticones, signos de puntuación y otras características de los caracteres como el número de mayúsculas, minúsculas, entre otros, con todo esto se usaron dos métodos \gls{SVM} y \gls{MaxEnt} el cuál parece funcionar muy bien para el inglés. Sin embargo, para el checo no es así ya que SVM tiene mayor puntaje en F-score (0.582) lo cual es muy bajo, esto según ellos fue porqué algunas muestras necesitaban conocimiento general, que con 6,700 muestras no fueron suficientes para obtener. Por otro lado en inglés, como ya se mencionó, sirvió mejor \gls{MaxEnt}, tal vez debido a que este clasificador no asume independencia entre las características. \gls{MaxEnt} dio un 0.923 de F-score, esto puede indicar que como \textcite{domingos2012few} menciona, hay dos formas de mejorar el desempeño de esta tarea, una es conseguir más datos y otra en mejorar o encontrar un algoritmo que requiera menos datos.

\par Respecto a los demás métodos, se puede destacar el trabajo de \textcite{reyes2012making} quienes principalmente describen una forma de cómo obtener el corpus y el trabajo de  \textcite{lopez2016character}, que obtuvo mejores resultados con un análisis a nivel de carácter, con un corpus no balanceado (30/70), tal vez debido a que en Twitter es necesario explotar más el potencial de los caracteres y suelen verse abreviaciones del texto, como por ejemplo  ``que'' pasa a ser ``q'', cuando el límite de caracteres se ha alcanzado en un tweet.

\par Como se ha podido ver, las redes neuronales se han ocupado para esta tarea; sin embargo, muchos sugieren que estas implementaciones pueden mejorarse. Las redes neuronales se han utilizado en la universidad de Stanford para crear el pie de figura de imágenes, Google las ocupa para reconocer los números de las casas en las fotos que toman sus automóviles y ubicarlas en el mapa, en Mountain View las ocupan para mejorar el reconocimiento de voz de  Android, ahorrar electricidad en sus servidores, y esto es solo una pequeña parte de sus aplicaciones. Lo anterior es una motivación para probar cómo se desempeñan las redes neuronales en esta tarea. 

\par El objetivo de esta tesis es proponer un modelo de red neuronal que pueda identificar ironía en textos cortos procedentes de Twitter. Dicha solución podría ayudar a los estudios de mercado que buscan la aceptación de un producto mediante el monitoreo de las redes sociales para la extracción de opiniones, incluso en campañas políticas, comerciales o movimientos sociales, ya que predeciría la opinión real de una persona sobre cierto tema. A su vez tiene conexión con otros problemas como la búsqueda de significados, minería de opiniones, modelos para detectar contradicciones, entre otros.


\par Debido a que las redes neuronales han tenido un desempeño excelente en una gran variedad de aplicaciones, es de esperarse obtener buenos resultados. En caso de que los resultados sean negativos, sería muy importante revisar los diferentes parámetros de la red neuronal que se pueden cambiar, por ejemplo, el número de capas ocultas, el número de nodos de cada capa, la normalización de los datos, la iniciación pseudoaleatoria de los pesos, para conseguir una mejor extracción de la información de los datos, que por ende mejore el desempeño del sistema.


\par La descripción del método es la siguiente:
\begin{itemize}
	\item Obtención del corpus
	\item Preprocesamiento de los documentos que componen el corpus (encaje o inmersión (en inglés \textit{embedding}), lexematización, normalización, lematización, conversión a vectores), explorar las diversas herramientas que ya existen y destacar la mejor de todas.
	\item Análisis de la red neuronal que mejor se adapta al problema, crear un conjunto de procedimientos viables para elegir los que podrían dar mejores resultados
	\item Diseño de los experimentos, diseñar las redes neuronales que resolverán la tarea
	\item Evaluación, elegir las métricas que mejor describan el desempeño del modelo
	\item Conclusiones, se dará una explicación de los resultados y se analizarán las oportunidades de crecimiento.
\end{itemize}

\par Para finalizar, la estructura de esta tesis es la siguiente: primero se presentarán algunos antecedentes y el estudio del estado de la técnica de la tarea que se propone, para después explicar un poco la teoría detrás del método que se usará para resolverla; por último se obtendrán resultados que se compararán con los obtenidos en la sección de antecedentes, para terminar con una conclusión y cuál podría ser el trabajo a futuro.

\par En este trabajo se usó el recurso de Google, llamado Colab Research, con el cual se puede usar un entorno de desarrollo en Python 2 o 3, usando como interfaz de desarrollo la aplicación web \textit{Jupyter}. La ventaja de usar esta herramienta es que se puede acceder al hardware de procesamiento de tensores de Google, \textit{unidad de procesamiento de tensores}(TPU por sus siglas en inglés), el cúal, por experiencia propia, llega a ser hasta 20 veces más rápido que usar una \textit{unidad de procesamiento gráfico} (GPU por sus siglas en inglés). Los experimentos realizados en esta tesis se encuentran disponibles en la siguiente liga \href{ https://drive.google.com/open?id=1oV5X1ZlOxXT-3nxp89BRwWcmSuSbOm43}{https://drive.google.com/open?id=1oV5X1ZlOxXT-3nxp89BRwWcmSuSbOm43}